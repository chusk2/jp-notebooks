{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install beautifulsoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/lib/python3.9/site-packages (4.9.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/lib/python3.9/site-packages (from beautifulsoup4) (2.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting an url from the internet  \n",
    "Don't forget to get the actual html content from the `request object` using the **`.text` attribute**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "url = 'https://raw.githubusercontent.com/techwithtim/Beautiful-Soup-Tutorial/main/index.html'\n",
    "html = requests.get(url)\n",
    "html_text = html.text\n",
    "soup = bs(html_text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('index.html', 'r') as file:\n",
    "#     content = BeautifulSoup(file, 'html.parser')\n",
    "# # prettify is a method to print the html file in HTML original form\n",
    "# print(content.prettify())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To access an html tag inside the html file, access it as an attribute of the BeautifulSoup object.  \n",
    "Use the `.string` attribute to access its content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>Your Title Here</title>\n",
      "Your Title Here\n"
     ]
    }
   ],
   "source": [
    "title =soup.title\n",
    "# the whole html tag\n",
    "print(title)\n",
    "# only the content inside the html tag\n",
    "print(title.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change the content of an html tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old title tag content:\n",
      "Your Title Here\n",
      "Now the <title> tag has new content:\n",
      "A new title for the html file\n"
     ]
    }
   ],
   "source": [
    "print('Old title tag content:')\n",
    "print(title.string)\n",
    "title.string = 'A new title for the html file'\n",
    "print('Now the <title> tag has new content:')\n",
    "print(title.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with `.find()` method you can get the first concurrence of a specific tag giving the method the tag type as an argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a href=\"http://somegreatsite.com\">Link Name</a>\n"
     ]
    }
   ],
   "source": [
    "# get the first <a> tag\n",
    "first_link = soup.find('a')\n",
    "print(first_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `.find_all(tag type)` to get all tags inside the html file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a href=\"http://somegreatsite.com\">Link Name</a>\n",
      "***************\n",
      "<a href=\"mailto:support@yourcompany.com\">\n",
      "\n",
      "support@yourcompany.com</a>\n"
     ]
    }
   ],
   "source": [
    "links = soup.find_all('a')\n",
    "print(*links, sep='\\n'+'*'*15 + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of the `.find_all()` method is a list of tags. Use slicing to get only some of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 <p> tags.\n",
      "Here they are:\n",
      "<p> This is a new paragraph!\n",
      "\n",
      "<p> <b color=\"red\">This is a new paragraph!</b>\n",
      "<br/> <b><i>This is a new sentence without a paragraph break, in bold italics.</i></b>\n",
      "<hr/>\n",
      "</p></p>\n",
      "<p> <b color=\"red\">This is a new paragraph!</b>\n",
      "<br/> <b><i>This is a new sentence without a paragraph break, in bold italics.</i></b>\n",
      "<hr/>\n",
      "</p>\n",
      "\n",
      "\n",
      "The first one is:\n",
      "<p> This is a new paragraph!\n",
      "\n",
      "<p> <b color=\"red\">This is a new paragraph!</b>\n",
      "<br/> <b><i>This is a new sentence without a paragraph break, in bold italics.</i></b>\n",
      "<hr/>\n",
      "</p></p>\n"
     ]
    }
   ],
   "source": [
    "p = soup.find_all('p')\n",
    "print(f'There are {len(p)} <p> tags.')\n",
    "print('Here they are:')\n",
    "for i in p:\n",
    "    print(i)\n",
    "\n",
    "print('\\n\\nThe first one is:')\n",
    "print(p[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modifying the attributes of an html tag  \n",
    "Tag attributes can be accessed as it is a dictionary, where keys are the attribute itself and value is the attribute's value. This dictionary can be shown using the bs object's attribute `.attrs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a href=\"http://somegreatsite.com\">Link Name</a>\n",
      "{'href': 'http://somegreatsite.com'}\n"
     ]
    }
   ],
   "source": [
    "first_a = soup.find('a')\n",
    "print(first_link)\n",
    "# attributes of a tag\n",
    "print(first_link.attrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's change its `href` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a href=\"www.google.es\">Link Name</a>\n"
     ]
    }
   ],
   "source": [
    "first_link['href'] = 'www.google.es'\n",
    "print(first_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding an html attribute to a tag  \n",
    "It is as simple as adding a new `key:value` pair to the `.attrs` dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a href=\"www.google.es\" target=\"_blank\">Link Name</a>\n"
     ]
    }
   ],
   "source": [
    "first_link['target'] = '_blank'\n",
    "print(first_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding multiple types of tag  \n",
    "Give a list of tag strings as argument of `.find` or `.find_all` methods. The result is a list of bs objects, or simply said, list of tags."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Previously I will import a new html file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('index2.html', 'r') as file:\n",
    "    soup2 = bs(file, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p>W3docs provides free learning materials for programming languages\n",
      "          like HTML, CSS, Java Script, PHP etc.</p>\n",
      "<a class=\"btn-item\" href=\"https://www.w3docs.com/learn-html.html\">Learn\n",
      "            HTML</a>\n",
      "<a class=\"btn-item\" href=\"https://www.w3docs.com/quiz/#\">Select Quiz</a>\n",
      "<a href=\"https://www.w3docs.com/privacy-policy\">Privacy Poalicy for\n",
      "              W3Docs.</a>\n"
     ]
    }
   ],
   "source": [
    "tags = soup2.find_all(['a', 'p'])\n",
    "for tag in tags:\n",
    "    print(tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find a tag with combination of tag name and text inside the tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<option selected=\"\" value=\"course-type\">Course type*</option>\n",
      "<option value=\"short-courses\">Short courses</option>\n",
      "<option value=\"featured-courses\">Featured courses</option>\n",
      "<option value=\"undergraduate\">Undergraduate</option>\n",
      "<option value=\"diploma\">Diploma</option>\n",
      "<option value=\"certificate\">Certificate</option>\n",
      "<option value=\"masters-degree\">Masters degree</option>\n",
      "<option value=\"postgraduate\">Postgraduate</option>\n",
      "\n",
      "---------------\n",
      "Only this one option is for \"Ungraduate\"\n",
      "[<option value=\"undergraduate\">Undergraduate</option>]\n",
      "Only this one option is for \"Ungraduate\"\n"
     ]
    }
   ],
   "source": [
    "options = soup2.find_all('option')\n",
    "print(*options, sep='\\n')\n",
    "print('\\n' + '-'*15)\n",
    "print('Only this one option is for \"Ungraduate\"')\n",
    "print(soup2.find_all('option', text='Undergraduate'))\n",
    "print('Only this one option is for \"Ungraduate\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search for specific attribute value inside the tag  \n",
    "Give argument for `.find_all` as follows: `tag attribute name = value`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a class=\"btn-item\" href=\"https://www.w3docs.com/learn-html.html\">Learn\n",
      "            HTML</a>\n",
      "<a class=\"btn-item\" href=\"https://www.w3docs.com/quiz/#\">Select Quiz</a>\n",
      "<a href=\"https://www.w3docs.com/privacy-policy\">Privacy Poalicy for\n",
      "              W3Docs.</a>\n",
      "\n",
      "\n",
      "Only this one points to the quiz site:\n",
      "[<a class=\"btn-item\" href=\"https://www.w3docs.com/quiz/#\">Select Quiz</a>]\n"
     ]
    }
   ],
   "source": [
    "links = soup2.find_all('a')\n",
    "print(*links, sep='\\n')\n",
    "print('\\n\\nOnly this one points to the quiz site:')\n",
    "print(soup2.find_all(href = \"https://www.w3docs.com/quiz/#\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search by class attribute  \n",
    "argument `class_` must be used. It is important to add the **`_`** underscore at the end of the `class_` keyword to differentiate from `class` object keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a class=\"btn-item\" href=\"https://www.w3docs.com/learn-html.html\">Learn\n",
      "            HTML</a>\n",
      "<a class=\"btn-item\" href=\"https://www.w3docs.com/quiz/#\">Select Quiz</a>\n"
     ]
    }
   ],
   "source": [
    "links_btn = soup2.find_all('a', class_='btn-item')\n",
    "print(*links_btn, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search using regular expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n        $2345\\n      ', '\\n        $123\\n        ']\n",
      "Cleaning the result...\n",
      "$2345\n",
      "$123\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "price_tags = soup2.find_all(text=re.compile('\\$.*'))\n",
    "print(price_tags)\n",
    "print('Cleaning the result...')\n",
    "for i in price_tags:\n",
    "    print(i.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limiting the number of results of find_all  \n",
    "Use of `limit` as key argument for `.find_all()`method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Course type*\n",
      "Short courses\n",
      "Featured courses\n",
      "Undergraduate\n",
      "Diploma\n",
      "Certificate\n",
      "Masters degree\n",
      "Postgraduate\n"
     ]
    }
   ],
   "source": [
    "options = soup2.find_all('option')\n",
    "for i in options:\n",
    "    print(i.string)\n",
    "\n",
    "# for div in divs:\n",
    "#     print(div, sep='n' + '*'*15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "limit the results to the 3 first ocurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Course type*\n",
      "Short courses\n",
      "Featured courses\n"
     ]
    }
   ],
   "source": [
    "\n",
    "options = soup2.find_all('option', limit=3)\n",
    "for i in options:\n",
    "    print(i.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the changes to a modified html file  \n",
    "`str(bs html object)` gives us the plain text html representation of the bs object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('index.modified.html', 'w') as file:\n",
    "    file.write(str(soup2))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
